{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4ffebd5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-05T00:40:26.227946Z",
     "iopub.status.busy": "2025-12-05T00:40:26.227627Z",
     "iopub.status.idle": "2025-12-05T00:40:27.468989Z",
     "shell.execute_reply": "2025-12-05T00:40:27.468302Z"
    },
    "papermill": {
     "duration": 1.246368,
     "end_time": "2025-12-05T00:40:27.470487",
     "exception": false,
     "start_time": "2025-12-05T00:40:26.224119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'GAT'...\r\n",
      "remote: Enumerating objects: 83, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (83/83), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (56/56), done.\u001b[K\r\n",
      "remote: Total 83 (delta 41), reused 61 (delta 26), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (83/83), 54.35 KiB | 1.43 MiB/s, done.\r\n",
      "Resolving deltas: 100% (41/41), done.\r\n"
     ]
    }
   ],
   "source": [
    "# Znak wykrzyknika (!) pozwala wywołać komendy systemowe Linuxa\n",
    "!git clone https://github.com/WebCrawlerr/GAT.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb6a8dfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:40:27.476166Z",
     "iopub.status.busy": "2025-12-05T00:40:27.475912Z",
     "iopub.status.idle": "2025-12-05T00:40:27.591428Z",
     "shell.execute_reply": "2025-12-05T00:40:27.590687Z"
    },
    "papermill": {
     "duration": 0.119819,
     "end_time": "2025-12-05T00:40:27.592779",
     "exception": false,
     "start_time": "2025-12-05T00:40:27.472960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any parent up to mount point /kaggle)\r\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\r\n"
     ]
    }
   ],
   "source": [
    "# Pobranie zmian\n",
    "!git pull origin main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c9652d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:40:27.598346Z",
     "iopub.status.busy": "2025-12-05T00:40:27.598115Z",
     "iopub.status.idle": "2025-12-05T00:40:27.722532Z",
     "shell.execute_reply": "2025-12-05T00:40:27.721883Z"
    },
    "papermill": {
     "duration": 0.128652,
     "end_time": "2025-12-05T00:40:27.723777",
     "exception": false,
     "start_time": "2025-12-05T00:40:27.595125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT:\r\n",
      "main.py  requirements.txt  src\ttests\r\n",
      "\r\n",
      "GAT/src:\r\n",
      "config.py\t    dataset.py\t model.py     train.py\r\n",
      "data_processing.py  features.py  __pycache__  utils.py\r\n",
      "\r\n",
      "GAT/src/__pycache__:\r\n",
      "config.cpython-312.pyc\t\t features.cpython-312.pyc\r\n",
      "data_processing.cpython-312.pyc  train.cpython-312.pyc\r\n",
      "dataset.cpython-312.pyc\t\t utils.cpython-312.pyc\r\n",
      "\r\n",
      "GAT/tests:\r\n",
      "test_cv.py  test_features.py  test_pipeline.py\ttest_plotting.py\r\n"
     ]
    }
   ],
   "source": [
    "# Wyświetla listę plików w pobranym folderze\n",
    "!ls -R  GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18a0b5bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:40:27.729338Z",
     "iopub.status.busy": "2025-12-05T00:40:27.729116Z",
     "iopub.status.idle": "2025-12-05T00:40:27.733741Z",
     "shell.execute_reply": "2025-12-05T00:40:27.733209Z"
    },
    "papermill": {
     "duration": 0.00853,
     "end_time": "2025-12-05T00:40:27.734652",
     "exception": false,
     "start_time": "2025-12-05T00:40:27.726122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktualny katalog: /kaggle/working/GAT\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "# 1. Zmiana katalogu roboczego (odpowiednik komendy 'cd')\n",
    "os.chdir('./GAT')\n",
    "print(f\"Aktualny katalog: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb4a5619",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-12-05T00:40:27.739855Z",
     "iopub.status.busy": "2025-12-05T00:40:27.739656Z",
     "iopub.status.idle": "2025-12-05T00:41:50.297029Z",
     "shell.execute_reply": "2025-12-05T00:41:50.295899Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 82.561944,
     "end_time": "2025-12-05T00:41:50.298722",
     "exception": false,
     "start_time": "2025-12-05T00:40:27.736778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "Instaluję dla: torch-260 + cu124\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\r\n",
      "Collecting pyg_lib\r\n",
      "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/pyg_lib-0.5.0%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (4.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torch_scatter\r\n",
      "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_scatter-2.1.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m115.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torch_sparse\r\n",
      "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_sparse-0.6.18%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (5.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torch_cluster\r\n",
      "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_cluster-1.6.3%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torch_spline_conv\r\n",
      "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_spline_conv-1.2.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (1.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.15.3)\r\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_sparse) (1.26.4)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch_sparse) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch_sparse) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch_sparse) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch_sparse) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch_sparse) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch_sparse) (2.4.1)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy->torch_sparse) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy->torch_sparse) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy->torch_sparse) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.5,>=1.23.5->scipy->torch_sparse) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.5,>=1.23.5->scipy->torch_sparse) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.5,>=1.23.5->scipy->torch_sparse) (2024.2.0)\r\n",
      "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\r\n",
      "Successfully installed pyg_lib-0.5.0+pt26cu124 torch_cluster-1.6.3+pt26cu124 torch_scatter-2.1.2+pt26cu124 torch_sparse-0.6.18+pt26cu124 torch_spline_conv-1.2.2+pt26cu124\r\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.6.0+cu124)\r\n",
      "Collecting torch-geometric>=2.3.0 (from -r requirements.txt (line 2))\r\n",
      "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting rdkit>=2023.3.1 (from -r requirements.txt (line 3))\r\n",
      "  Downloading rdkit-2025.9.3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.2 kB)\r\n",
      "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.2.3)\r\n",
      "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.26.4)\r\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (3.7.2)\r\n",
      "Requirement already satisfied: seaborn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.12.2)\r\n",
      "Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (1.2.2)\r\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (4.67.1)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.20.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (4.15.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2025.10.0)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 1))\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 1))\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 1))\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->-r requirements.txt (line 1))\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->-r requirements.txt (line 1))\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->-r requirements.txt (line 1))\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->-r requirements.txt (line 1))\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->-r requirements.txt (line 1))\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->-r requirements.txt (line 1))\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 1))\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->-r requirements.txt (line 1)) (1.3.0)\r\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric>=2.3.0->-r requirements.txt (line 2)) (3.13.2)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric>=2.3.0->-r requirements.txt (line 2)) (7.1.3)\r\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric>=2.3.0->-r requirements.txt (line 2)) (3.0.9)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric>=2.3.0->-r requirements.txt (line 2)) (2.32.5)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from torch-geometric>=2.3.0->-r requirements.txt (line 2)) (3.6.0)\r\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit>=2023.3.1->-r requirements.txt (line 3)) (11.3.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 4)) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 4)) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 4)) (2025.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->-r requirements.txt (line 5)) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->-r requirements.txt (line 5)) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->-r requirements.txt (line 5)) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->-r requirements.txt (line 5)) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->-r requirements.txt (line 5)) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->-r requirements.txt (line 5)) (2.4.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 6)) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 6)) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 6)) (4.59.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 6)) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 6)) (25.0)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.0->-r requirements.txt (line 8)) (1.15.3)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.0->-r requirements.txt (line 8)) (1.5.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.0->-r requirements.txt (line 8)) (3.6.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r requirements.txt (line 4)) (1.17.0)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->-r requirements.txt (line 2)) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->-r requirements.txt (line 2)) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->-r requirements.txt (line 2)) (25.4.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->-r requirements.txt (line 2)) (1.8.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->-r requirements.txt (line 2)) (6.7.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->-r requirements.txt (line 2)) (0.4.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->-r requirements.txt (line 2)) (1.22.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 1)) (3.0.3)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.0->-r requirements.txt (line 5)) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.0->-r requirements.txt (line 5)) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.0->-r requirements.txt (line 5)) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.24.0->-r requirements.txt (line 5)) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.24.0->-r requirements.txt (line 5)) (2024.2.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric>=2.3.0->-r requirements.txt (line 2)) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric>=2.3.0->-r requirements.txt (line 2)) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric>=2.3.0->-r requirements.txt (line 2)) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric>=2.3.0->-r requirements.txt (line 2)) (2025.10.5)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.24.0->-r requirements.txt (line 5)) (2024.2.0)\r\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rdkit-2025.9.3-cp311-cp311-manylinux_2_28_x86_64.whl (36.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch-geometric, rdkit\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 rdkit-2025.9.3 torch-geometric-2.7.0\r\n"
     ]
    }
   ],
   "source": [
    "# Najpierw sprawdźmy wersję po restarcie (czasem GPU ma starszego PyTorcha)\n",
    "import torch\n",
    "version = torch.__version__\n",
    "print(f\"PyTorch version: {version}\")\n",
    "\n",
    "# Instalacja PyG i bibliotek pomocniczych (korzystamy z gotowych paczek .whl, żeby nie kompilować przez 20 min)\n",
    "# UWAGA: Ta komenda dynamicznie dobiera link do wersji Twojego PyTorcha\n",
    "torch_version_suffix = version.split('+')[0].replace('.', '') # np. 260 lub 240\n",
    "cuda_version_suffix = 'cu' + torch.version.cuda.replace('.', '') # np. cu121\n",
    "\n",
    "print(f\"Instaluję dla: torch-{torch_version_suffix} + {cuda_version_suffix}\")\n",
    "\n",
    "# Instalacja zależności\n",
    "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv \\\n",
    "  -f https://data.pyg.org/whl/torch-{version}.html\n",
    "\n",
    "# Instalacja reszty z Twojego pliku (bez ponownego instalowania torch-geometric, bo zrobiliśmy to wyżej)\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79d0e05e",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-12-05T00:41:50.362467Z",
     "iopub.status.busy": "2025-12-05T00:41:50.361602Z",
     "iopub.status.idle": "2025-12-05T00:42:01.017751Z",
     "shell.execute_reply": "2025-12-05T00:42:01.016948Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 10.695513,
     "end_time": "2025-12-05T00:42:01.018998",
     "exception": false,
     "start_time": "2025-12-05T00:41:50.323485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA dostępne: True\n",
      "Wersja PyTorch: 2.6.0+cu124\n",
      "Wersja PyG: 2.7.0\n",
      "✅ GATConv zaimportowany pomyślnie!\n",
      "✅ torch_scatter obecny\n",
      "✅ torch_sparse obecny\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "print(f\"CUDA dostępne: {torch.cuda.is_available()}\")\n",
    "print(f\"Wersja PyTorch: {torch.__version__}\")\n",
    "print(f\"Wersja PyG: {torch_geometric.__version__}\")\n",
    "\n",
    "# Próba importu kluczowych warstw\n",
    "try:\n",
    "    from torch_geometric.nn import GATConv\n",
    "    print(\"✅ GATConv zaimportowany pomyślnie!\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Błąd importu GATConv: {e}\")\n",
    "\n",
    "# Sprawdzenie czy mamy backendy (scatter/sparse)\n",
    "# PyG 2.7+ potrafi czasem działać bez nich (wolniej), ale warto sprawdzić\n",
    "try:\n",
    "    import torch_scatter\n",
    "    print(\"✅ torch_scatter obecny\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ torch_scatter BRAK (Może to spowolnić trening lub wywołać błąd)\")\n",
    "\n",
    "try:\n",
    "    import torch_sparse\n",
    "    print(\"✅ torch_sparse obecny\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ torch_sparse BRAK (Wymagany dla niektórych operatorów)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab31958d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:42:01.064335Z",
     "iopub.status.busy": "2025-12-05T00:42:01.063586Z",
     "iopub.status.idle": "2025-12-05T01:25:03.013434Z",
     "shell.execute_reply": "2025-12-05T01:25:03.012594Z"
    },
    "papermill": {
     "duration": 2581.973679,
     "end_time": "2025-12-05T01:25:03.014942",
     "exception": false,
     "start_time": "2025-12-05T00:42:01.041263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GAT BRD4 Binding Prediction Pipeline...\r\n",
      "Loading and filtering data from /kaggle/input/bindingdb-smiles/BindingDB_All.tsv in chunks of 100000...\r\n",
      "Processed 1000000 rows...\r\n",
      "Processed 2000000 rows...\r\n",
      "Processed 3000000 rows...\r\n",
      "Finished processing 3078912 rows.\r\n",
      "Found 22758 records for BRD4.\r\n",
      "Cleaning and Labeling...\r\n",
      "Final dataset size: 22616\r\n",
      "Creating Graph Dataset in ./data/processed (this may take a while)...\r\n",
      "Processing...\r\n",
      "Processing Molecules:  12%|█▋             | 2618/22616 [00:03<00:26, 750.90it/s][00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 18 19 23\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 23 24 28\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 20 21 25\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 20 21 25\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 5\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 5\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 20 21 23\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 3 4 5\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 3 4 5\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 20 21 23\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "Processing Molecules:  12%|█▊             | 2722/22616 [00:04<00:23, 834.69it/s][00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 36 37 39\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 36 37 39\r\n",
      "Processing Molecules:  12%|█▊             | 2813/22616 [00:04<00:23, 853.54it/s][00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 29 30 32\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 29 30 32\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 31 32 34\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 31 32 34\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 28 29 31\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 28 29 31\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "Processing Molecules:  13%|█▉             | 2980/22616 [00:04<00:27, 725.49it/s][00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 4 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 23 24 27\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 23 24 27\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:53] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:54] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:54] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:54] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:54] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:54] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:54] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:54] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:54] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:54] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:54] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:54] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:54] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:54] Can't kekulize mol.  Unkekulized atoms: 2 4 7\r\n",
      "[00:45:54] Can't kekulize mol.  Unkekulized atoms: 2 4 7\r\n",
      "[00:45:54] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "Processing Molecules:  14%|██             | 3059/22616 [00:04<00:26, 742.34it/s][00:45:54] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:54] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:54] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:54] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:54] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:54] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:54] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:54] Explicit valence for atom # 3 F, 3, is greater than permitted\r\n",
      "Processing Molecules:  16%|██▍            | 3718/22616 [00:05<00:29, 647.94it/s][00:45:55] Explicit valence for atom # 23 N, 4, is greater than permitted\r\n",
      "Processing Molecules:  17%|██▌            | 3786/22616 [00:05<00:28, 656.52it/s][00:45:55] Can't kekulize mol.  Unkekulized atoms: 34 35 38\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 34 35 38\r\n",
      "[00:45:55] Explicit valence for atom # 4 N, 4, is greater than permitted\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "Processing Molecules:  17%|██▌            | 3852/22616 [00:05<00:29, 632.84it/s][00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 3 6\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "Processing Molecules:  19%|██▊            | 4187/22616 [00:06<00:32, 564.13it/s][00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "Processing Molecules:  19%|██▊            | 4246/22616 [00:06<00:32, 570.04it/s][00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 30 31 33\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 30 31 33\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 24 25 27\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 24 25 27\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 24 25 27\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 24 25 27\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "[00:45:55] Can't kekulize mol.  Unkekulized atoms: 1 2 6\r\n",
      "Processing Molecules:  23%|███▍           | 5273/22616 [00:07<00:23, 734.15it/s][00:45:57] Explicit valence for atom # 24 N, 4, is greater than permitted\r\n",
      "[00:45:57] Explicit valence for atom # 24 N, 4, is greater than permitted\r\n",
      "[00:45:57] Explicit valence for atom # 24 N, 4, is greater than permitted\r\n",
      "[00:45:57] Explicit valence for atom # 24 N, 4, is greater than permitted\r\n",
      "Processing Molecules:  25%|███▊           | 5660/22616 [00:08<00:21, 776.74it/s][00:45:57] Explicit valence for atom # 12 N, 4, is greater than permitted\r\n",
      "Processing Molecules:  26%|███▉           | 5978/22616 [00:08<00:23, 696.76it/s][00:45:58] Explicit valence for atom # 6 N, 4, is greater than permitted\r\n",
      "Processing Molecules:  34%|█████▏         | 7765/22616 [00:11<00:21, 693.97it/s][00:46:01] Can't kekulize mol.  Unkekulized atoms: 26 27 28 29 31\r\n",
      "[00:46:01] Can't kekulize mol.  Unkekulized atoms: 26 27 28 29 31\r\n",
      "Processing Molecules: 100%|██████████████| 22616/22616 [00:34<00:00, 651.82it/s]\r\n",
      "Processing complete. Successfully processed: 22421. Failed: 195.\r\n",
      "Done!\r\n",
      "Starting 5-Fold Scaffold Cross-Validation...\r\n",
      "\r\n",
      "--- Fold 1/5 ---\r\n",
      "Train: 17941, Val: 4480\r\n",
      "Using device: cuda for Fold 0\r\n",
      "Epoch: 001, Loss: 0.3043, Val AP: 0.8417, Val AUC: 0.7512\r\n",
      "Epoch: 002, Loss: 0.2822, Val AP: 0.8488, Val AUC: 0.7585\r\n",
      "Epoch: 003, Loss: 0.2718, Val AP: 0.8590, Val AUC: 0.7725\r\n",
      "Epoch: 004, Loss: 0.2647, Val AP: 0.8555, Val AUC: 0.7681\r\n",
      "Epoch: 005, Loss: 0.2620, Val AP: 0.8597, Val AUC: 0.7723\r\n",
      "Epoch: 006, Loss: 0.2611, Val AP: 0.8638, Val AUC: 0.7748\r\n",
      "Epoch: 007, Loss: 0.2579, Val AP: 0.8703, Val AUC: 0.7842\r\n",
      "Epoch: 008, Loss: 0.2571, Val AP: 0.8672, Val AUC: 0.7790\r\n",
      "Epoch: 009, Loss: 0.2555, Val AP: 0.8739, Val AUC: 0.7888\r\n",
      "Epoch: 010, Loss: 0.2534, Val AP: 0.8713, Val AUC: 0.7860\r\n",
      "Epoch: 011, Loss: 0.2523, Val AP: 0.8770, Val AUC: 0.7925\r\n",
      "Epoch: 012, Loss: 0.2524, Val AP: 0.8841, Val AUC: 0.8035\r\n",
      "Epoch: 013, Loss: 0.2504, Val AP: 0.8853, Val AUC: 0.8043\r\n",
      "Epoch: 014, Loss: 0.2478, Val AP: 0.8892, Val AUC: 0.8115\r\n",
      "Epoch: 015, Loss: 0.2465, Val AP: 0.8877, Val AUC: 0.8077\r\n",
      "Epoch: 016, Loss: 0.2449, Val AP: 0.8997, Val AUC: 0.8255\r\n",
      "Epoch: 017, Loss: 0.2439, Val AP: 0.8982, Val AUC: 0.8243\r\n",
      "Epoch: 018, Loss: 0.2425, Val AP: 0.8996, Val AUC: 0.8273\r\n",
      "Epoch: 019, Loss: 0.2412, Val AP: 0.9084, Val AUC: 0.8410\r\n",
      "Epoch: 020, Loss: 0.2396, Val AP: 0.9035, Val AUC: 0.8343\r\n",
      "Epoch: 021, Loss: 0.2403, Val AP: 0.9068, Val AUC: 0.8386\r\n",
      "Epoch: 022, Loss: 0.2389, Val AP: 0.9054, Val AUC: 0.8328\r\n",
      "Epoch: 023, Loss: 0.2371, Val AP: 0.9074, Val AUC: 0.8410\r\n",
      "Epoch: 024, Loss: 0.2358, Val AP: 0.9050, Val AUC: 0.8366\r\n",
      "Epoch: 025, Loss: 0.2354, Val AP: 0.9142, Val AUC: 0.8481\r\n",
      "Epoch: 026, Loss: 0.2364, Val AP: 0.9103, Val AUC: 0.8435\r\n",
      "Epoch: 027, Loss: 0.2340, Val AP: 0.9148, Val AUC: 0.8471\r\n",
      "Epoch: 028, Loss: 0.2334, Val AP: 0.9068, Val AUC: 0.8371\r\n",
      "Epoch: 029, Loss: 0.2335, Val AP: 0.9167, Val AUC: 0.8490\r\n",
      "Epoch: 030, Loss: 0.2323, Val AP: 0.9182, Val AUC: 0.8532\r\n",
      "Epoch: 031, Loss: 0.2299, Val AP: 0.9150, Val AUC: 0.8499\r\n",
      "Epoch: 032, Loss: 0.2290, Val AP: 0.9241, Val AUC: 0.8591\r\n",
      "Epoch: 033, Loss: 0.2303, Val AP: 0.9179, Val AUC: 0.8470\r\n",
      "Epoch: 034, Loss: 0.2298, Val AP: 0.9184, Val AUC: 0.8525\r\n",
      "Epoch: 035, Loss: 0.2281, Val AP: 0.9246, Val AUC: 0.8600\r\n",
      "Epoch: 036, Loss: 0.2291, Val AP: 0.9158, Val AUC: 0.8501\r\n",
      "Epoch: 037, Loss: 0.2288, Val AP: 0.9155, Val AUC: 0.8499\r\n",
      "Epoch: 038, Loss: 0.2289, Val AP: 0.9213, Val AUC: 0.8560\r\n",
      "Epoch: 039, Loss: 0.2281, Val AP: 0.9198, Val AUC: 0.8536\r\n",
      "Epoch: 040, Loss: 0.2282, Val AP: 0.9219, Val AUC: 0.8550\r\n",
      "Epoch: 041, Loss: 0.2271, Val AP: 0.9187, Val AUC: 0.8555\r\n",
      "Epoch: 042, Loss: 0.2265, Val AP: 0.9236, Val AUC: 0.8571\r\n",
      "Epoch: 043, Loss: 0.2262, Val AP: 0.9254, Val AUC: 0.8629\r\n",
      "Epoch: 044, Loss: 0.2268, Val AP: 0.9183, Val AUC: 0.8532\r\n",
      "Epoch: 045, Loss: 0.2230, Val AP: 0.9295, Val AUC: 0.8610\r\n",
      "Epoch: 046, Loss: 0.2260, Val AP: 0.9241, Val AUC: 0.8579\r\n",
      "Epoch: 047, Loss: 0.2248, Val AP: 0.9268, Val AUC: 0.8612\r\n",
      "Epoch: 048, Loss: 0.2244, Val AP: 0.9278, Val AUC: 0.8614\r\n",
      "Epoch: 049, Loss: 0.2232, Val AP: 0.9245, Val AUC: 0.8577\r\n",
      "Epoch: 050, Loss: 0.2226, Val AP: 0.9311, Val AUC: 0.8652\r\n",
      "Epoch: 051, Loss: 0.2230, Val AP: 0.9243, Val AUC: 0.8608\r\n",
      "Epoch: 052, Loss: 0.2236, Val AP: 0.9285, Val AUC: 0.8613\r\n",
      "Epoch: 053, Loss: 0.2216, Val AP: 0.9302, Val AUC: 0.8627\r\n",
      "Epoch: 054, Loss: 0.2211, Val AP: 0.9325, Val AUC: 0.8665\r\n",
      "Epoch: 055, Loss: 0.2236, Val AP: 0.9260, Val AUC: 0.8623\r\n",
      "Epoch: 056, Loss: 0.2218, Val AP: 0.9296, Val AUC: 0.8657\r\n",
      "Epoch: 057, Loss: 0.2229, Val AP: 0.9302, Val AUC: 0.8642\r\n",
      "Epoch: 058, Loss: 0.2203, Val AP: 0.9331, Val AUC: 0.8681\r\n",
      "Epoch: 059, Loss: 0.2198, Val AP: 0.9301, Val AUC: 0.8642\r\n",
      "Epoch: 060, Loss: 0.2221, Val AP: 0.9316, Val AUC: 0.8664\r\n",
      "Epoch: 061, Loss: 0.2201, Val AP: 0.9324, Val AUC: 0.8664\r\n",
      "Epoch: 062, Loss: 0.2214, Val AP: 0.9334, Val AUC: 0.8672\r\n",
      "Epoch: 063, Loss: 0.2226, Val AP: 0.9352, Val AUC: 0.8713\r\n",
      "Epoch: 064, Loss: 0.2209, Val AP: 0.9299, Val AUC: 0.8659\r\n",
      "Epoch: 065, Loss: 0.2219, Val AP: 0.9308, Val AUC: 0.8663\r\n",
      "Epoch: 066, Loss: 0.2195, Val AP: 0.9346, Val AUC: 0.8722\r\n",
      "Epoch: 067, Loss: 0.2230, Val AP: 0.9281, Val AUC: 0.8597\r\n",
      "Epoch: 068, Loss: 0.2192, Val AP: 0.9363, Val AUC: 0.8742\r\n",
      "Epoch: 069, Loss: 0.2183, Val AP: 0.9300, Val AUC: 0.8678\r\n",
      "Epoch: 070, Loss: 0.2221, Val AP: 0.9330, Val AUC: 0.8696\r\n",
      "Epoch: 071, Loss: 0.2200, Val AP: 0.9268, Val AUC: 0.8588\r\n",
      "Epoch: 072, Loss: 0.2191, Val AP: 0.9347, Val AUC: 0.8730\r\n",
      "Epoch: 073, Loss: 0.2208, Val AP: 0.9328, Val AUC: 0.8704\r\n",
      "Epoch: 074, Loss: 0.2189, Val AP: 0.9342, Val AUC: 0.8743\r\n",
      "Epoch: 075, Loss: 0.2202, Val AP: 0.9387, Val AUC: 0.8768\r\n",
      "Epoch: 076, Loss: 0.2180, Val AP: 0.9321, Val AUC: 0.8695\r\n",
      "Epoch: 077, Loss: 0.2191, Val AP: 0.9351, Val AUC: 0.8728\r\n",
      "Epoch: 078, Loss: 0.2194, Val AP: 0.9312, Val AUC: 0.8691\r\n",
      "Epoch: 079, Loss: 0.2176, Val AP: 0.9388, Val AUC: 0.8762\r\n",
      "Epoch: 080, Loss: 0.2190, Val AP: 0.9352, Val AUC: 0.8727\r\n",
      "Epoch: 081, Loss: 0.2188, Val AP: 0.9328, Val AUC: 0.8705\r\n",
      "Epoch: 082, Loss: 0.2174, Val AP: 0.9289, Val AUC: 0.8610\r\n",
      "Epoch: 083, Loss: 0.2179, Val AP: 0.9343, Val AUC: 0.8718\r\n",
      "Epoch: 084, Loss: 0.2187, Val AP: 0.9353, Val AUC: 0.8739\r\n",
      "Epoch: 085, Loss: 0.2177, Val AP: 0.9344, Val AUC: 0.8729\r\n",
      "Epoch: 086, Loss: 0.2211, Val AP: 0.9355, Val AUC: 0.8735\r\n",
      "Epoch: 087, Loss: 0.2177, Val AP: 0.9254, Val AUC: 0.8593\r\n",
      "Epoch: 088, Loss: 0.2169, Val AP: 0.9399, Val AUC: 0.8794\r\n",
      "Epoch: 089, Loss: 0.2200, Val AP: 0.9362, Val AUC: 0.8761\r\n",
      "Epoch: 090, Loss: 0.2172, Val AP: 0.9363, Val AUC: 0.8736\r\n",
      "Epoch: 091, Loss: 0.2177, Val AP: 0.9360, Val AUC: 0.8750\r\n",
      "Epoch: 092, Loss: 0.2173, Val AP: 0.9377, Val AUC: 0.8764\r\n",
      "Epoch: 093, Loss: 0.2179, Val AP: 0.9353, Val AUC: 0.8751\r\n",
      "Epoch: 094, Loss: 0.2185, Val AP: 0.9379, Val AUC: 0.8805\r\n",
      "Epoch: 095, Loss: 0.2168, Val AP: 0.9431, Val AUC: 0.8845\r\n",
      "Epoch: 096, Loss: 0.2172, Val AP: 0.9401, Val AUC: 0.8808\r\n",
      "Epoch: 097, Loss: 0.2176, Val AP: 0.9407, Val AUC: 0.8833\r\n",
      "Epoch: 098, Loss: 0.2197, Val AP: 0.9323, Val AUC: 0.8696\r\n",
      "Epoch: 099, Loss: 0.2163, Val AP: 0.9385, Val AUC: 0.8797\r\n",
      "Epoch: 100, Loss: 0.2178, Val AP: 0.9383, Val AUC: 0.8809\r\n",
      "Loading best model for final evaluation (fold_0_best_model.pth)...\r\n",
      "Validation Metrics: {'AUC': 0.8845020472459018, 'AP': 0.9430965824447333, 'F1': 0.8261401362921544}\r\n",
      "\r\n",
      "--- Fold 2/5 ---\r\n",
      "Train: 17924, Val: 4497\r\n",
      "Using device: cuda for Fold 1\r\n",
      "Epoch: 001, Loss: 0.2996, Val AP: 0.8328, Val AUC: 0.7412\r\n",
      "Epoch: 002, Loss: 0.2792, Val AP: 0.8467, Val AUC: 0.7613\r\n",
      "Epoch: 003, Loss: 0.2705, Val AP: 0.8587, Val AUC: 0.7751\r\n",
      "Epoch: 004, Loss: 0.2658, Val AP: 0.8558, Val AUC: 0.7746\r\n",
      "Epoch: 005, Loss: 0.2651, Val AP: 0.8672, Val AUC: 0.7867\r\n",
      "Epoch: 006, Loss: 0.2632, Val AP: 0.8691, Val AUC: 0.7913\r\n",
      "Epoch: 007, Loss: 0.2609, Val AP: 0.8673, Val AUC: 0.7885\r\n",
      "Epoch: 008, Loss: 0.2608, Val AP: 0.8700, Val AUC: 0.7923\r\n",
      "Epoch: 009, Loss: 0.2596, Val AP: 0.8737, Val AUC: 0.7954\r\n",
      "Epoch: 010, Loss: 0.2580, Val AP: 0.8735, Val AUC: 0.7979\r\n",
      "Epoch: 011, Loss: 0.2560, Val AP: 0.8756, Val AUC: 0.8007\r\n",
      "Epoch: 012, Loss: 0.2565, Val AP: 0.8738, Val AUC: 0.7999\r\n",
      "Epoch: 013, Loss: 0.2536, Val AP: 0.8726, Val AUC: 0.7994\r\n",
      "Epoch: 014, Loss: 0.2528, Val AP: 0.8759, Val AUC: 0.8027\r\n",
      "Epoch: 015, Loss: 0.2515, Val AP: 0.8764, Val AUC: 0.8025\r\n",
      "Epoch: 016, Loss: 0.2499, Val AP: 0.8796, Val AUC: 0.8068\r\n",
      "Epoch: 017, Loss: 0.2495, Val AP: 0.8799, Val AUC: 0.8056\r\n",
      "Epoch: 018, Loss: 0.2489, Val AP: 0.8831, Val AUC: 0.8105\r\n",
      "Epoch: 019, Loss: 0.2484, Val AP: 0.8846, Val AUC: 0.8134\r\n",
      "Epoch: 020, Loss: 0.2461, Val AP: 0.8822, Val AUC: 0.8107\r\n",
      "Epoch: 021, Loss: 0.2471, Val AP: 0.8826, Val AUC: 0.8107\r\n",
      "Epoch: 022, Loss: 0.2436, Val AP: 0.8833, Val AUC: 0.8136\r\n",
      "Epoch: 023, Loss: 0.2406, Val AP: 0.8840, Val AUC: 0.8146\r\n",
      "Epoch: 024, Loss: 0.2419, Val AP: 0.8865, Val AUC: 0.8173\r\n",
      "Epoch: 025, Loss: 0.2383, Val AP: 0.8851, Val AUC: 0.8142\r\n",
      "Epoch: 026, Loss: 0.2353, Val AP: 0.8866, Val AUC: 0.8192\r\n",
      "Epoch: 027, Loss: 0.2354, Val AP: 0.8900, Val AUC: 0.8156\r\n",
      "Epoch: 028, Loss: 0.2348, Val AP: 0.8898, Val AUC: 0.8224\r\n",
      "Epoch: 029, Loss: 0.2330, Val AP: 0.8859, Val AUC: 0.8243\r\n",
      "Epoch: 030, Loss: 0.2314, Val AP: 0.8906, Val AUC: 0.8286\r\n",
      "Epoch: 031, Loss: 0.2289, Val AP: 0.8936, Val AUC: 0.8268\r\n",
      "Epoch: 032, Loss: 0.2318, Val AP: 0.8895, Val AUC: 0.8272\r\n",
      "Epoch: 033, Loss: 0.2280, Val AP: 0.8893, Val AUC: 0.8296\r\n",
      "Epoch: 034, Loss: 0.2276, Val AP: 0.8910, Val AUC: 0.8328\r\n",
      "Epoch: 035, Loss: 0.2271, Val AP: 0.8972, Val AUC: 0.8361\r\n",
      "Epoch: 036, Loss: 0.2258, Val AP: 0.8931, Val AUC: 0.8337\r\n",
      "Epoch: 037, Loss: 0.2244, Val AP: 0.8924, Val AUC: 0.8303\r\n",
      "Epoch: 038, Loss: 0.2250, Val AP: 0.8915, Val AUC: 0.8342\r\n",
      "Epoch: 039, Loss: 0.2237, Val AP: 0.8960, Val AUC: 0.8342\r\n",
      "Epoch: 040, Loss: 0.2230, Val AP: 0.8959, Val AUC: 0.8392\r\n",
      "Epoch: 041, Loss: 0.2238, Val AP: 0.8935, Val AUC: 0.8422\r\n",
      "Epoch: 042, Loss: 0.2223, Val AP: 0.8945, Val AUC: 0.8359\r\n",
      "Epoch: 043, Loss: 0.2223, Val AP: 0.8970, Val AUC: 0.8371\r\n",
      "Epoch: 044, Loss: 0.2215, Val AP: 0.8971, Val AUC: 0.8424\r\n",
      "Epoch: 045, Loss: 0.2192, Val AP: 0.8992, Val AUC: 0.8403\r\n",
      "Epoch: 046, Loss: 0.2210, Val AP: 0.8961, Val AUC: 0.8299\r\n",
      "Epoch: 047, Loss: 0.2209, Val AP: 0.8969, Val AUC: 0.8414\r\n",
      "Epoch: 048, Loss: 0.2202, Val AP: 0.8981, Val AUC: 0.8410\r\n",
      "Epoch: 049, Loss: 0.2192, Val AP: 0.8966, Val AUC: 0.8442\r\n",
      "Epoch: 050, Loss: 0.2194, Val AP: 0.8999, Val AUC: 0.8410\r\n",
      "Epoch: 051, Loss: 0.2171, Val AP: 0.9013, Val AUC: 0.8459\r\n",
      "Epoch: 052, Loss: 0.2193, Val AP: 0.8987, Val AUC: 0.8411\r\n",
      "Epoch: 053, Loss: 0.2167, Val AP: 0.9008, Val AUC: 0.8440\r\n",
      "Epoch: 054, Loss: 0.2185, Val AP: 0.9011, Val AUC: 0.8473\r\n",
      "Epoch: 055, Loss: 0.2161, Val AP: 0.9058, Val AUC: 0.8448\r\n",
      "Epoch: 056, Loss: 0.2160, Val AP: 0.9070, Val AUC: 0.8495\r\n",
      "Epoch: 057, Loss: 0.2146, Val AP: 0.9051, Val AUC: 0.8509\r\n",
      "Epoch: 058, Loss: 0.2160, Val AP: 0.9111, Val AUC: 0.8522\r\n",
      "Epoch: 059, Loss: 0.2148, Val AP: 0.9041, Val AUC: 0.8499\r\n",
      "Epoch: 060, Loss: 0.2140, Val AP: 0.9024, Val AUC: 0.8460\r\n",
      "Epoch: 061, Loss: 0.2155, Val AP: 0.9024, Val AUC: 0.8481\r\n",
      "Epoch: 062, Loss: 0.2136, Val AP: 0.9046, Val AUC: 0.8502\r\n",
      "Epoch: 063, Loss: 0.2119, Val AP: 0.9038, Val AUC: 0.8487\r\n",
      "Epoch: 064, Loss: 0.2122, Val AP: 0.9077, Val AUC: 0.8535\r\n",
      "Epoch: 065, Loss: 0.2141, Val AP: 0.9077, Val AUC: 0.8513\r\n",
      "Epoch: 066, Loss: 0.2141, Val AP: 0.9106, Val AUC: 0.8532\r\n",
      "Epoch: 067, Loss: 0.2118, Val AP: 0.9103, Val AUC: 0.8554\r\n",
      "Epoch: 068, Loss: 0.2117, Val AP: 0.9069, Val AUC: 0.8473\r\n",
      "Early stopping triggered.\r\n",
      "Loading best model for final evaluation (fold_1_best_model.pth)...\r\n",
      "Validation Metrics: {'AUC': 0.8522448186985842, 'AP': 0.9110667043029506, 'F1': 0.8555315972798142}\r\n",
      "\r\n",
      "--- Fold 3/5 ---\r\n",
      "Train: 17941, Val: 4480\r\n",
      "Using device: cuda for Fold 2\r\n",
      "Epoch: 001, Loss: 0.3336, Val AP: 0.8989, Val AUC: 0.7622\r\n",
      "Epoch: 002, Loss: 0.3117, Val AP: 0.9100, Val AUC: 0.7861\r\n",
      "Epoch: 003, Loss: 0.3022, Val AP: 0.9167, Val AUC: 0.8012\r\n",
      "Epoch: 004, Loss: 0.2963, Val AP: 0.9291, Val AUC: 0.8237\r\n",
      "Epoch: 005, Loss: 0.2913, Val AP: 0.9335, Val AUC: 0.8328\r\n",
      "Epoch: 006, Loss: 0.2856, Val AP: 0.9387, Val AUC: 0.8500\r\n",
      "Epoch: 007, Loss: 0.2785, Val AP: 0.9429, Val AUC: 0.8549\r\n",
      "Epoch: 008, Loss: 0.2744, Val AP: 0.9432, Val AUC: 0.8604\r\n",
      "Epoch: 009, Loss: 0.2665, Val AP: 0.9458, Val AUC: 0.8686\r\n",
      "Epoch: 010, Loss: 0.2636, Val AP: 0.9419, Val AUC: 0.8663\r\n",
      "Epoch: 011, Loss: 0.2617, Val AP: 0.9494, Val AUC: 0.8707\r\n",
      "Epoch: 012, Loss: 0.2579, Val AP: 0.9428, Val AUC: 0.8718\r\n",
      "Epoch: 013, Loss: 0.2561, Val AP: 0.9514, Val AUC: 0.8755\r\n",
      "Epoch: 014, Loss: 0.2522, Val AP: 0.9454, Val AUC: 0.8750\r\n",
      "Epoch: 015, Loss: 0.2513, Val AP: 0.9523, Val AUC: 0.8754\r\n",
      "Epoch: 016, Loss: 0.2490, Val AP: 0.9540, Val AUC: 0.8728\r\n",
      "Epoch: 017, Loss: 0.2484, Val AP: 0.9533, Val AUC: 0.8783\r\n",
      "Epoch: 018, Loss: 0.2484, Val AP: 0.9544, Val AUC: 0.8783\r\n",
      "Epoch: 019, Loss: 0.2457, Val AP: 0.9572, Val AUC: 0.8824\r\n",
      "Epoch: 020, Loss: 0.2493, Val AP: 0.9557, Val AUC: 0.8812\r\n",
      "Epoch: 021, Loss: 0.2456, Val AP: 0.9527, Val AUC: 0.8802\r\n",
      "Epoch: 022, Loss: 0.2444, Val AP: 0.9585, Val AUC: 0.8845\r\n",
      "Epoch: 023, Loss: 0.2460, Val AP: 0.9503, Val AUC: 0.8760\r\n",
      "Epoch: 024, Loss: 0.2424, Val AP: 0.9518, Val AUC: 0.8769\r\n",
      "Epoch: 025, Loss: 0.2427, Val AP: 0.9458, Val AUC: 0.8688\r\n",
      "Epoch: 026, Loss: 0.2417, Val AP: 0.9561, Val AUC: 0.8793\r\n",
      "Epoch: 027, Loss: 0.2427, Val AP: 0.9598, Val AUC: 0.8842\r\n",
      "Epoch: 028, Loss: 0.2399, Val AP: 0.9608, Val AUC: 0.8886\r\n",
      "Epoch: 029, Loss: 0.2409, Val AP: 0.9619, Val AUC: 0.8879\r\n",
      "Epoch: 030, Loss: 0.2404, Val AP: 0.9576, Val AUC: 0.8790\r\n",
      "Epoch: 031, Loss: 0.2383, Val AP: 0.9535, Val AUC: 0.8777\r\n",
      "Epoch: 032, Loss: 0.2396, Val AP: 0.9610, Val AUC: 0.8884\r\n",
      "Epoch: 033, Loss: 0.2391, Val AP: 0.9627, Val AUC: 0.8904\r\n",
      "Epoch: 034, Loss: 0.2369, Val AP: 0.9593, Val AUC: 0.8826\r\n",
      "Epoch: 035, Loss: 0.2393, Val AP: 0.9592, Val AUC: 0.8855\r\n",
      "Epoch: 036, Loss: 0.2398, Val AP: 0.9598, Val AUC: 0.8863\r\n",
      "Epoch: 037, Loss: 0.2404, Val AP: 0.9579, Val AUC: 0.8869\r\n",
      "Epoch: 038, Loss: 0.2377, Val AP: 0.9591, Val AUC: 0.8879\r\n",
      "Epoch: 039, Loss: 0.2385, Val AP: 0.9613, Val AUC: 0.8891\r\n",
      "Epoch: 040, Loss: 0.2364, Val AP: 0.9589, Val AUC: 0.8839\r\n",
      "Epoch: 041, Loss: 0.2379, Val AP: 0.9580, Val AUC: 0.8866\r\n",
      "Epoch: 042, Loss: 0.2365, Val AP: 0.9605, Val AUC: 0.8882\r\n",
      "Epoch: 043, Loss: 0.2365, Val AP: 0.9607, Val AUC: 0.8848\r\n",
      "Early stopping triggered.\r\n",
      "Loading best model for final evaluation (fold_2_best_model.pth)...\r\n",
      "Validation Metrics: {'AUC': 0.8903511200952565, 'AP': 0.9627402549790712, 'F1': 0.9075727037143679}\r\n",
      "\r\n",
      "--- Fold 4/5 ---\r\n",
      "Train: 17941, Val: 4480\r\n",
      "Using device: cuda for Fold 3\r\n",
      "Epoch: 001, Loss: 0.3319, Val AP: 0.9159, Val AUC: 0.8021\r\n",
      "Epoch: 002, Loss: 0.3096, Val AP: 0.9155, Val AUC: 0.8123\r\n",
      "Epoch: 003, Loss: 0.3033, Val AP: 0.9266, Val AUC: 0.8319\r\n",
      "Epoch: 004, Loss: 0.2974, Val AP: 0.9261, Val AUC: 0.8316\r\n",
      "Epoch: 005, Loss: 0.2932, Val AP: 0.9304, Val AUC: 0.8350\r\n",
      "Epoch: 006, Loss: 0.2913, Val AP: 0.9326, Val AUC: 0.8439\r\n",
      "Epoch: 007, Loss: 0.2892, Val AP: 0.9362, Val AUC: 0.8477\r\n",
      "Epoch: 008, Loss: 0.2889, Val AP: 0.9350, Val AUC: 0.8474\r\n",
      "Epoch: 009, Loss: 0.2843, Val AP: 0.9356, Val AUC: 0.8476\r\n",
      "Epoch: 010, Loss: 0.2845, Val AP: 0.9394, Val AUC: 0.8547\r\n",
      "Epoch: 011, Loss: 0.2777, Val AP: 0.9404, Val AUC: 0.8557\r\n",
      "Epoch: 012, Loss: 0.2711, Val AP: 0.9458, Val AUC: 0.8646\r\n",
      "Epoch: 013, Loss: 0.2694, Val AP: 0.9442, Val AUC: 0.8621\r\n",
      "Epoch: 014, Loss: 0.2668, Val AP: 0.9454, Val AUC: 0.8645\r\n",
      "Epoch: 015, Loss: 0.2648, Val AP: 0.9476, Val AUC: 0.8689\r\n",
      "Epoch: 016, Loss: 0.2643, Val AP: 0.9471, Val AUC: 0.8683\r\n",
      "Epoch: 017, Loss: 0.2642, Val AP: 0.9471, Val AUC: 0.8683\r\n",
      "Epoch: 018, Loss: 0.2635, Val AP: 0.9459, Val AUC: 0.8655\r\n",
      "Epoch: 019, Loss: 0.2615, Val AP: 0.9487, Val AUC: 0.8733\r\n",
      "Epoch: 020, Loss: 0.2618, Val AP: 0.9479, Val AUC: 0.8699\r\n",
      "Epoch: 021, Loss: 0.2613, Val AP: 0.9500, Val AUC: 0.8749\r\n",
      "Epoch: 022, Loss: 0.2596, Val AP: 0.9460, Val AUC: 0.8670\r\n",
      "Epoch: 023, Loss: 0.2609, Val AP: 0.9493, Val AUC: 0.8755\r\n",
      "Epoch: 024, Loss: 0.2605, Val AP: 0.9501, Val AUC: 0.8771\r\n",
      "Epoch: 025, Loss: 0.2617, Val AP: 0.9498, Val AUC: 0.8762\r\n",
      "Epoch: 026, Loss: 0.2590, Val AP: 0.9511, Val AUC: 0.8776\r\n",
      "Epoch: 027, Loss: 0.2582, Val AP: 0.9524, Val AUC: 0.8787\r\n",
      "Epoch: 028, Loss: 0.2575, Val AP: 0.9522, Val AUC: 0.8793\r\n",
      "Epoch: 029, Loss: 0.2536, Val AP: 0.9533, Val AUC: 0.8820\r\n",
      "Epoch: 030, Loss: 0.2557, Val AP: 0.9538, Val AUC: 0.8817\r\n",
      "Epoch: 031, Loss: 0.2550, Val AP: 0.9526, Val AUC: 0.8819\r\n",
      "Epoch: 032, Loss: 0.2555, Val AP: 0.9546, Val AUC: 0.8866\r\n",
      "Epoch: 033, Loss: 0.2522, Val AP: 0.9537, Val AUC: 0.8826\r\n",
      "Epoch: 034, Loss: 0.2501, Val AP: 0.9540, Val AUC: 0.8853\r\n",
      "Epoch: 035, Loss: 0.2525, Val AP: 0.9535, Val AUC: 0.8844\r\n",
      "Epoch: 036, Loss: 0.2511, Val AP: 0.9541, Val AUC: 0.8832\r\n",
      "Epoch: 037, Loss: 0.2501, Val AP: 0.9518, Val AUC: 0.8816\r\n",
      "Epoch: 038, Loss: 0.2507, Val AP: 0.9534, Val AUC: 0.8830\r\n",
      "Epoch: 039, Loss: 0.2496, Val AP: 0.9515, Val AUC: 0.8815\r\n",
      "Epoch: 040, Loss: 0.2487, Val AP: 0.9528, Val AUC: 0.8841\r\n",
      "Epoch: 041, Loss: 0.2509, Val AP: 0.9518, Val AUC: 0.8827\r\n",
      "Epoch: 042, Loss: 0.2466, Val AP: 0.9528, Val AUC: 0.8851\r\n",
      "Early stopping triggered.\r\n",
      "Loading best model for final evaluation (fold_3_best_model.pth)...\r\n",
      "Validation Metrics: {'AUC': 0.8865864870120721, 'AP': 0.9545902738061245, 'F1': 0.8937378568225975}\r\n",
      "\r\n",
      "--- Fold 5/5 ---\r\n",
      "Train: 17937, Val: 4484\r\n",
      "Using device: cuda for Fold 4\r\n",
      "Epoch: 001, Loss: 0.3124, Val AP: 0.8695, Val AUC: 0.7521\r\n",
      "Epoch: 002, Loss: 0.2919, Val AP: 0.8764, Val AUC: 0.7653\r\n",
      "Epoch: 003, Loss: 0.2827, Val AP: 0.8897, Val AUC: 0.7817\r\n",
      "Epoch: 004, Loss: 0.2786, Val AP: 0.8912, Val AUC: 0.7852\r\n",
      "Epoch: 005, Loss: 0.2752, Val AP: 0.8948, Val AUC: 0.7902\r\n",
      "Epoch: 006, Loss: 0.2709, Val AP: 0.9014, Val AUC: 0.7995\r\n",
      "Epoch: 007, Loss: 0.2683, Val AP: 0.9000, Val AUC: 0.7977\r\n",
      "Epoch: 008, Loss: 0.2621, Val AP: 0.9021, Val AUC: 0.8043\r\n",
      "Epoch: 009, Loss: 0.2562, Val AP: 0.9009, Val AUC: 0.8030\r\n",
      "Epoch: 010, Loss: 0.2518, Val AP: 0.9053, Val AUC: 0.8099\r\n",
      "Epoch: 011, Loss: 0.2465, Val AP: 0.9029, Val AUC: 0.8162\r\n",
      "Epoch: 012, Loss: 0.2452, Val AP: 0.9140, Val AUC: 0.8285\r\n",
      "Epoch: 013, Loss: 0.2388, Val AP: 0.9072, Val AUC: 0.8182\r\n",
      "Epoch: 014, Loss: 0.2372, Val AP: 0.9172, Val AUC: 0.8357\r\n",
      "Epoch: 015, Loss: 0.2337, Val AP: 0.9138, Val AUC: 0.8320\r\n",
      "Epoch: 016, Loss: 0.2328, Val AP: 0.9169, Val AUC: 0.8360\r\n",
      "Epoch: 017, Loss: 0.2331, Val AP: 0.9107, Val AUC: 0.8244\r\n",
      "Epoch: 018, Loss: 0.2305, Val AP: 0.9168, Val AUC: 0.8357\r\n",
      "Epoch: 019, Loss: 0.2305, Val AP: 0.9169, Val AUC: 0.8382\r\n",
      "Epoch: 020, Loss: 0.2297, Val AP: 0.9169, Val AUC: 0.8352\r\n",
      "Epoch: 021, Loss: 0.2283, Val AP: 0.9168, Val AUC: 0.8401\r\n",
      "Epoch: 022, Loss: 0.2265, Val AP: 0.9198, Val AUC: 0.8413\r\n",
      "Epoch: 023, Loss: 0.2292, Val AP: 0.9170, Val AUC: 0.8379\r\n",
      "Epoch: 024, Loss: 0.2254, Val AP: 0.9188, Val AUC: 0.8380\r\n",
      "Epoch: 025, Loss: 0.2256, Val AP: 0.9174, Val AUC: 0.8390\r\n",
      "Epoch: 026, Loss: 0.2247, Val AP: 0.9157, Val AUC: 0.8359\r\n",
      "Epoch: 027, Loss: 0.2240, Val AP: 0.9213, Val AUC: 0.8443\r\n",
      "Epoch: 028, Loss: 0.2230, Val AP: 0.9174, Val AUC: 0.8395\r\n",
      "Epoch: 029, Loss: 0.2218, Val AP: 0.9202, Val AUC: 0.8411\r\n",
      "Epoch: 030, Loss: 0.2215, Val AP: 0.9243, Val AUC: 0.8488\r\n",
      "Epoch: 031, Loss: 0.2220, Val AP: 0.9225, Val AUC: 0.8434\r\n",
      "Epoch: 032, Loss: 0.2215, Val AP: 0.9187, Val AUC: 0.8402\r\n",
      "Epoch: 033, Loss: 0.2199, Val AP: 0.9244, Val AUC: 0.8479\r\n",
      "Epoch: 034, Loss: 0.2222, Val AP: 0.9257, Val AUC: 0.8506\r\n",
      "Epoch: 035, Loss: 0.2201, Val AP: 0.9234, Val AUC: 0.8465\r\n",
      "Epoch: 036, Loss: 0.2202, Val AP: 0.9152, Val AUC: 0.8345\r\n",
      "Epoch: 037, Loss: 0.2191, Val AP: 0.9245, Val AUC: 0.8470\r\n",
      "Epoch: 038, Loss: 0.2203, Val AP: 0.9248, Val AUC: 0.8489\r\n",
      "Epoch: 039, Loss: 0.2201, Val AP: 0.9207, Val AUC: 0.8422\r\n",
      "Epoch: 040, Loss: 0.2185, Val AP: 0.9258, Val AUC: 0.8505\r\n",
      "Epoch: 041, Loss: 0.2170, Val AP: 0.9267, Val AUC: 0.8518\r\n",
      "Epoch: 042, Loss: 0.2192, Val AP: 0.9221, Val AUC: 0.8449\r\n",
      "Epoch: 043, Loss: 0.2187, Val AP: 0.9255, Val AUC: 0.8486\r\n",
      "Epoch: 044, Loss: 0.2182, Val AP: 0.9269, Val AUC: 0.8535\r\n",
      "Epoch: 045, Loss: 0.2190, Val AP: 0.9255, Val AUC: 0.8522\r\n",
      "Epoch: 046, Loss: 0.2161, Val AP: 0.9247, Val AUC: 0.8510\r\n",
      "Epoch: 047, Loss: 0.2165, Val AP: 0.9262, Val AUC: 0.8525\r\n",
      "Epoch: 048, Loss: 0.2155, Val AP: 0.9226, Val AUC: 0.8460\r\n",
      "Epoch: 049, Loss: 0.2159, Val AP: 0.9246, Val AUC: 0.8498\r\n",
      "Epoch: 050, Loss: 0.2163, Val AP: 0.9272, Val AUC: 0.8541\r\n",
      "Epoch: 051, Loss: 0.2158, Val AP: 0.9285, Val AUC: 0.8564\r\n",
      "Epoch: 052, Loss: 0.2158, Val AP: 0.9264, Val AUC: 0.8534\r\n",
      "Epoch: 053, Loss: 0.2176, Val AP: 0.9242, Val AUC: 0.8501\r\n",
      "Epoch: 054, Loss: 0.2147, Val AP: 0.9261, Val AUC: 0.8533\r\n",
      "Epoch: 055, Loss: 0.2147, Val AP: 0.9277, Val AUC: 0.8549\r\n",
      "Epoch: 056, Loss: 0.2148, Val AP: 0.9244, Val AUC: 0.8489\r\n",
      "Epoch: 057, Loss: 0.2144, Val AP: 0.9224, Val AUC: 0.8449\r\n",
      "Epoch: 058, Loss: 0.2147, Val AP: 0.9294, Val AUC: 0.8580\r\n",
      "Epoch: 059, Loss: 0.2162, Val AP: 0.9282, Val AUC: 0.8555\r\n",
      "Epoch: 060, Loss: 0.2151, Val AP: 0.9293, Val AUC: 0.8577\r\n",
      "Epoch: 061, Loss: 0.2144, Val AP: 0.9275, Val AUC: 0.8543\r\n",
      "Epoch: 062, Loss: 0.2166, Val AP: 0.9253, Val AUC: 0.8506\r\n",
      "Epoch: 063, Loss: 0.2131, Val AP: 0.9276, Val AUC: 0.8526\r\n",
      "Epoch: 064, Loss: 0.2145, Val AP: 0.9305, Val AUC: 0.8599\r\n",
      "Epoch: 065, Loss: 0.2159, Val AP: 0.9251, Val AUC: 0.8486\r\n",
      "Epoch: 066, Loss: 0.2136, Val AP: 0.9292, Val AUC: 0.8567\r\n",
      "Epoch: 067, Loss: 0.2132, Val AP: 0.9285, Val AUC: 0.8545\r\n",
      "Epoch: 068, Loss: 0.2146, Val AP: 0.9259, Val AUC: 0.8503\r\n",
      "Epoch: 069, Loss: 0.2157, Val AP: 0.9275, Val AUC: 0.8521\r\n",
      "Epoch: 070, Loss: 0.2147, Val AP: 0.9323, Val AUC: 0.8617\r\n",
      "Epoch: 071, Loss: 0.2125, Val AP: 0.9281, Val AUC: 0.8550\r\n",
      "Epoch: 072, Loss: 0.2132, Val AP: 0.9309, Val AUC: 0.8584\r\n",
      "Epoch: 073, Loss: 0.2115, Val AP: 0.9322, Val AUC: 0.8601\r\n",
      "Epoch: 074, Loss: 0.2115, Val AP: 0.9309, Val AUC: 0.8615\r\n",
      "Epoch: 075, Loss: 0.2132, Val AP: 0.9283, Val AUC: 0.8560\r\n",
      "Epoch: 076, Loss: 0.2124, Val AP: 0.9298, Val AUC: 0.8582\r\n",
      "Epoch: 077, Loss: 0.2104, Val AP: 0.9322, Val AUC: 0.8613\r\n",
      "Epoch: 078, Loss: 0.2153, Val AP: 0.9321, Val AUC: 0.8610\r\n",
      "Epoch: 079, Loss: 0.2125, Val AP: 0.9306, Val AUC: 0.8581\r\n",
      "Epoch: 080, Loss: 0.2133, Val AP: 0.9305, Val AUC: 0.8579\r\n",
      "Early stopping triggered.\r\n",
      "Loading best model for final evaluation (fold_4_best_model.pth)...\r\n",
      "Validation Metrics: {'AUC': 0.8617700905518191, 'AP': 0.9323042735418003, 'F1': 0.7934231240160923}\r\n",
      "\r\n",
      "=== Cross-Validation Results ===\r\n",
      "Mean AUC: 0.8751 +/- 0.0152\r\n",
      "Mean AP: 0.9408 +/- 0.0181\r\n",
      "Mean F1: 0.8553 +/- 0.0422\r\n",
      "Pipeline Completed.\r\n"
     ]
    }
   ],
   "source": [
    "!python main.py --raw_file /kaggle/input/bindingdb-smiles/BindingDB_All.tsv --processed_dir ./data/processed --cv 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27cbbbda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T01:25:03.112288Z",
     "iopub.status.busy": "2025-12-05T01:25:03.111986Z",
     "iopub.status.idle": "2025-12-05T01:25:03.120395Z",
     "shell.execute_reply": "2025-12-05T01:25:03.119706Z"
    },
    "papermill": {
     "duration": 0.058927,
     "end_time": "2025-12-05T01:25:03.121563",
     "exception": false,
     "start_time": "2025-12-05T01:25:03.062636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Nie znaleziono pliku ZIP. Upewnij się, że poprzednia komórka wykonała się bez błędów.\n",
      "Lista plików w obecnym folderze:\n",
      "['fold_4_roc_curve.png', 'fold_3_training_curves.png', 'requirements.txt', '.gitignore', 'models', 'fold_2_pr_curve.png', 'fold_0_pr_curve.png', 'fold_1_pr_curve.png', 'fold_4_pr_curve.png', 'data', 'fold_0_confusion_matrix.png', 'fold_0_roc_curve.png', 'fold_0_training_curves.png', 'fold_2_training_curves.png', 'fold_1_training_curves.png', 'fold_3_roc_curve.png', 'fold_1_roc_curve.png', 'fold_3_pr_curve.png', 'fold_2_confusion_matrix.png', 'fold_4_training_curves.png', 'fold_4_confusion_matrix.png', 'fold_3_confusion_matrix.png', 'main.py', 'fold_1_confusion_matrix.png', 'fold_2_roc_curve.png', 'tests', 'src', '.git']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Nazwa pliku, którego szukamy\n",
    "zip_name = 'GAT_BRD4_Results.zip'\n",
    "\n",
    "# 1. Znajdź plik w całym systemie plików roboczych\n",
    "found_path = None\n",
    "for root, dirs, files in os.walk('/kaggle/working'):\n",
    "    if zip_name in files:\n",
    "        found_path = os.path.join(root, zip_name)\n",
    "        break\n",
    "\n",
    "if found_path:\n",
    "    print(f\"✅ Znaleziono plik tutaj: {found_path}\")\n",
    "    \n",
    "    # 2. Przenieś go do głównego katalogu (Dla pewności)\n",
    "    target_path = f'/kaggle/working/{zip_name}'\n",
    "    \n",
    "    if found_path != target_path:\n",
    "        shutil.move(found_path, target_path)\n",
    "        print(f\"📦 Przeniesiono plik do głównego katalogu: {target_path}\")\n",
    "    \n",
    "    # 3. Zmień katalog roboczy na główny (żeby FileLink zadziałał)\n",
    "    os.chdir('/kaggle/working')\n",
    "    \n",
    "    # 4. Wyświetl link\n",
    "    print(\"👇 Kliknij poniżej:\")\n",
    "    display(FileLink(zip_name))\n",
    "else:\n",
    "    print(\"❌ Nie znaleziono pliku ZIP. Upewnij się, że poprzednia komórka wykonała się bez błędów.\")\n",
    "    # Sprawdźmy co w ogóle mamy na dysku\n",
    "    print(\"Lista plików w obecnym folderze:\")\n",
    "    print(os.listdir('.'))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8899363,
     "sourceId": 13960890,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2681.839247,
   "end_time": "2025-12-05T01:25:04.588388",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-05T00:40:22.749141",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
